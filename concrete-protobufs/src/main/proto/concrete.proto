/* 
 * Copyright 2012-2013 Johns Hopkins University HLTCOE. All rights reserved.
 * This software is released under the 2-clause BSD license.
 * See LICENSE in the project root directory.
 */

/**
 * Concrete - Rebar ProtoBuf serialization definitions
 * 
 */

option java_package="edu.jhu.hlt.concrete";
package concrete;

import "twitter.proto";

//===========================================================================
// Universally Unique Identifiers
//===========================================================================

//
// A 16-byte UUID identifier.
//
// @see http://en.wikipedia.org/wiki/Universally_unique_identifier 
//
message UUID {
  required fixed64 high = 1; //!< The 8 most significant bytes
  required fixed64 low = 2;  //!< The 8 least significant bytes
}

//===========================================================================
// Conventions
//===========================================================================

/**______________________________________________________________________
  * TIMES
  *     Times and dates are encoded as unix time UTC (i.e., seconds
  *     since January 1, 1970), stored in an int64 field.
  *______________________________________________________________________
  * LANGUAGES
  *     Languages are encoded using ISO 639-3 three-letter codes.
  *     Other language code formats, such as ISO 639-1 two-letter
  *     codes (<http://en.wikipedia.org/wiki/ISO_639-1>) and
  *     Ethnologue SIL codes (<http://www.ethnologue.com/codes/>)
  *     should be mapped to the corresponding ISO 639-3 code.
  * 
  *     Two special codes should be noted:
  *     <ul>
  *       <li> und: Language is undetermined </li>
  *       <li> zxx: No linguistic content </li>
  *     </ul>
  *______________________________________________________________________
  */ 

//===========================================================================
// Communications
//===========================================================================

/** A globally unique identifier for a communication object that comes
 * from a persistent corpus.  This identifier is meant to be stable,
 * and directly mappable back to the source document(s) in the
 * persistent corpus (unlike UUIDs, which are randomly generated). */
message CommunicationGUID {
  /** The name of the corpus.  Each corpus should be assigned
   * a globally unique name; ensuring this global uniqueness is 
   * the responsibility of the user. */
  optional string corpus_name = 1;

  /** A string identifier that uniquely identifies a single
   * communication within the corpus.  Typically this will be a file
   * or document identifier from the corpus.  In cases where a single
   * communication contains multiple files/documents, this identifier
   * may have a different form.
   *
   * This identifier is typically used to index the Communication
   * objects within a corpus -- i.e., if you wish to load a
   * Communication, then you need to know its communication_id. */
  optional string communication_id = 2; 
}

/** A single communication instance, containing linguistic content
  * generated by a single speaker or author.  This type is used for
  * both inter-personal communications (such as phone calls or
  * conversations) and third-party communications (such as news
  * articles).
  *
  * Each communication instance is grounded by its original
  * (unannotated) contents, which should be stored in either the
  * "text" field (for text communications) or the "audio" field (for
  * audio communications).  If the communication is not available in
  * its original form, then these fields should store the
  * communication in the least-processed form available.
  */
message Communication {
  /*========================== Identifiers ==========================*/

  /** Stable identifier for this communication, identifying both the
   * name of the source corpus and the document that it corresponds to
   * in that corpus. */
  required CommunicationGUID guid = 1;

  /** Universally unique identifier for this communication instance.
   * This is generated randomly, and can *not* be mapped back to the
   * source corpus.  It is used as a target for symbolic "pointers". */
  required UUID uuid = 2;

  /*=================== "Raw Input" Fields ====================== */

  /** The full text contents of this communication in its original
   * form, or in the least-processed form available, if the original
   * is not available. */
  optional string text = 3;

  /** The full audio contents of this communication in its original
   * form, or in the least-processed form available, if the original
   * is not available. */
  optional Sound audio = 4;
  
  /** The time when this communication started (in unix time UTC --
   * i.e., seconds since January 1, 1970).  */
  optional int64 start_time = 5;

  /** The time when this communication ended (in unix time UTC --
   * i.e., seconds since January 1, 1970). */
  optional int64 end_time = 6;

  /*=================== Annotation Fields ====================== */

  /** Theories about the block structure of this communication. */
  repeated SectionSegmentation section_segmentation = 8;

  /** Theories about the languages that are present in this
   * communication. */
  repeated LanguageIdentification language_id = 14;

  /** Theories about which spans of text are used to mention entities
   * in this communication. */
  repeated EntityMentionSet entity_mention_set = 9;

  /** Theories about what entities are discussed in this
   * communication, with pointers to individual mentions. */
  repeated EntitySet entity_set = 10;

  /** Theories about what situations are explicitly mentioned in this
   * communication. */
  repeated SituationMentionSet situation_mention_set = 20;

  /** Theories about what situations are asserted in this
   * communication. */
  repeated SituationSet situation_set = 21;

  /** Raw SERIF output for this communication. */
  repeated SerifXML serifxml = 18;
  
  /** key/value metadata field.*/
  repeated KeyValues metadata = 19;


  /*=================== Kind-Specific Fields ====================== */

  /** An enumeration used to indicate what type of communication this
    * is.  The optional fields named "<i>kind</i>_info" can be used to
    * store extra fields that are specific to the communication
    * type. */
  optional Kind kind = 15 [default=OTHER];
  enum Kind {
    OTHER = 0;
    EMAIL = 1;
    NEWS = 2;
    WIKIPEDIA = 3;
    TWEET = 4;
    PHONE_CALL = 5;
    // JCM
    USENET = 6;
    BLOG = 7;
    // This list is intended to grow over time.
  };

  /** Extra information for communications where kind==EMAIL */
  optional EmailCommunicationInfo email_info = 1001;
  /** Extra information for communications where kind==PHONE_CALL */
  optional PhoneCallCommunicationInfo phone_call_info = 1002;

  /** Extra information for communications where kind==TWEET:
   * Information about this tweet that is provided by the Twitter
   * API.  For information about the Twitter API, see:
   * <https://dev.twitter.com/docs/platform-objects> */
  optional TweetInfo tweet_info = 1004;
}

/** A theory about what languages are present in a given communication
 * or piece of communication.  Note that it is possible to have more
 * than one language present in a given communication. */
message LanguageIdentification {
  /** Unique identifier for this language identification. */
  required UUID uuid = 1;
  
  /** Information about where this language identification came from. */
  optional AnnotationMetadata metadata = 2;

  /** A list mapping from a language to the probability that that
   * language occurs in a given communication.  Each language code should
   * occur at most once in this list.  The probabilities do <i>not</i>
   * need to sum to one -- for example, if a single communication is known
   * to contain both English and French, then it would be appropriate
   * to assign a probability of 1 to both langauges.  (Manually
   * annotated LanguageProb objects should always have probabilities
   * of either zero or one; machine-generated LanguageProbs may have
   * intermediate probabilities.) */
  repeated LanguageProb language = 3;

  /** A message mapping a language to a probability */
  message LanguageProb {
    optional string language = 1;   //!< ISO 639-3 three-letter code
    optional float probability = 2;
  }
}

/** Extra information about an email communication instance. */
message EmailCommunicationInfo {
  // Information extracted from headers:
  optional string message_id = 1;
  optional string content_type = 2;
  optional string user_agent = 3;
  repeated string in_reply_to = 4; //!< defined by RFC 822, RFC 2822
  repeated string reference = 5; //!< defined by RFC 1036, RFC 2822
  optional EmailAddress senderAddress = 6;
  optional EmailAddress returnPathAddress = 7;
  repeated EmailAddress toAddress = 8;
  repeated EmailAddress ccAddress = 9;
  repeated EmailAddress bccAddress = 10;
}

/** An email address, optionally accompanied by a display_name.  These
  * values are typically extracted from strings such as: 
  * <tt> "John Smith" &lt;john\@xyz.com&gt; </tt>.
  * 
  * \see RFC2822 <http://tools.ietf.org/html/rfc2822>
  */
message EmailAddress {
  optional string address = 1;
  optional string display_name = 2;
}

/** Extra information about a phone-call communication instance. */
message PhoneCallCommunicationInfo {
  // etc.
}

message SerifXML {
  /** Unique identifier. */
  required UUID uuid = 1;

  /** Information about where this serifxml came from. */
  optional AnnotationMetadata metadata = 2;

  /** The xml itself */
  optional bytes xml = 3;

}

//===========================================================================
// Spans in Text/Audio
//===========================================================================

/** A span of text within a single communication, identified by a pair
 * of character offsets.  In this context, a "character offset" is a
 * zero-based count of UTF-16 codepoints.  I.e., if you are using
 * Java, or are using a Python build where sys.maxunicode==0xffff,
 * then the "character offset" is an offset into the standard
 * (unicode) string data type.  If you are using a Python build where
 * sys.maxunicode==0xffffffff, then you would need to encode the
 * unicode string using UTF-16 before using the character offsets. */
message TextSpan {
  /** Start character, inclusive. */
  optional uint32 start = 1;
  /** End character, exclusive */
  optional uint32 end = 2;
}

/** A span of audio within a single communication, identified by a
 * pair of time offests. Time offsets are zero-based.*/
message AudioSpan {
  /** Start time (in seconds)*/
  optional uint64 start = 1;
  /** End time (in seconds)*/
  optional uint64 end = 2;

  // NOTE: we reserve the right to add a "channel" field or something
  // analogous, for multi-channel audio (left/right, etc).
}

//==========================================================================
//Key/Value Metadata
//==========================================================================
message KeyValues {
    required string key = 1;
    repeated string values = 2;
}

//===========================================================================
// Sections (aka "Regions" or "Zones")
//===========================================================================

/** A theory about how a communication is broken down into smaller
 * sections (such as paragraphs).  The sections should be ordered
 * and non-overlapping. */
message SectionSegmentation {
  /** Unique identifier for this segmentation. */
  required UUID uuid = 1;
  
  /** Information about where this segmentation came from. */
  optional AnnotationMetadata metadata = 2;

  /** Ordered list of sections in this segmentation. */
  repeated Section section = 3;
}

/** A single "section" of a communication, such as a paragraph.  Each
 * section is defined using a text or audio span, and can optionally
 * contain a list of sentences. */
message Section {
  required UUID uuid = 1;

  /** Location of this section in the original text. */
  optional TextSpan text_span = 2;

  /** Location of this section in the original audio. */
  optional AudioSpan audio_span = 3;

  /** Theories about how this section is divided into sentences. */
  repeated SentenceSegmentation sentence_segmentation = 4;

  /** The type of this section. */
  required Kind kind = 5 [default=OTHER];
  enum Kind {
    OTHER = 0;
    // E.g., one or more paragraphs, or the full text of a tweet
    PASSAGE = 1;
    // E.g., the header text of an email from Enron
    METADATA = 2;
   // a bulleted list that is formatted such that we expect NLP tools to choke
    LIST = 3;
    // an embedded table that will almost certainly cause NLP tools to choke
    TABLE = 4;
    // TODO, include embedded image support when actually needed
    IMAGE = 5;
    // etc..
  }

 /**The name of the section **/
 optional string label = 10;

 /**Position within the communication with respect to other Sections: 
 The section number, E.g., 3, or 3.1, or 3.1.2, etc.  Aimed at
 Communications with content organized in a hierarchy, such as a Book
 with multiple chapters, then sections, then paragraphs. Or even a
 dense Wikipedia page with subsections.  Sections should still be
 arranged linearly, where reading these numbers should not be required
 to get a start-to-finish enumeration of the Communication's content.
 **/
 repeated int32 number = 11;

}

//===========================================================================
// Sentences
//===========================================================================

/** A theory about how a section of a communication is broken down
 * into sentences (or utterances).  The sentences in a
 * SentenceSegmentation should be ordered and non-overlapping. */
message SentenceSegmentation {
  /** Unique identifier for this segmentation. */
  required UUID uuid = 1;
  
  /** Information about where this segmentation came from. */
  optional AnnotationMetadata metadata = 2;

  /** Ordered list of sentences in this segmentation. */
  repeated Sentence sentence = 3;
}

/** A single sentence or utterance in a communication. */
message Sentence {
  /** Unique identifier for this sentence. */
  required UUID uuid = 1;

  /** Location of this sentence in the original text. */
  optional TextSpan text_span = 2;

  /** Location of this sentence in the original audio. */
  optional AudioSpan audio_span = 3;

  /** Theories about the tokens that make up this sentence.  For text
    * communications, these tokenizations will typically be generated
    * by a tokenizer.  For audio communications, these tokenizations
    * will typically be generated by an automatic speech recognizer. 
    *
    * The "Tokenization" message type is also used to store the output
    * of machine translation systems and text normalization
    * systems. */
  repeated Tokenization tokenization = 5;

}

//===========================================================================
// Tokens & Tokenizations
//===========================================================================

/** A single token (typically a word) in a communication.  The exact
  * definition of what counts as a token is left up to the tools that
  * generate token sequences.  
  *
  * Usually, each token will include at least a text string.
  */
message Token {
  /** A tokenization-relative identifier for this token.  Together
    * with the UUID for a Tokenization, this can be used to define
    * pointers to specific tokens.  If a Tokenization object contains
    * multiple Token objects with the same id (e.g., in different
    * n-best lists), then all of their other fields *must* be
    * identical as well. */
  // A 0-based index that represents the order that this token appears in the sentence. 
  required int32 token_index = 1;

  // The text associated with this token. 
  // Note - we may have a destructive tokenizer (e.g., Stanford rewriting)
  //   and as a result, we want to maintain this field. 
  required string text = 2;

  /** Location of this token in the original text.  In cases where
   * this token does not correspond directly with any text span in
   * the original text (such as word insertion during MT), this field
   * may be given a value indicating "approximately" where the token
   * comes from.  A span covering the entire sentence may be used if
   * no more precise value seems appropriate. */
  optional TextSpan text_span = 4;

  /** Location of this token in the original audio. */
  optional AudioSpan audio_span = 5;
}

/** A pointer to a token. */
message TokenRef {
  /** The tokenization-relative identifier for the token that is
    * pointed at. */
  required int32 token_index = 1;

  /** The UUID of the tokenization that contains the token. */
  required UUID tokenization_id = 2;
}

/** A list of pointers to tokens that all belong to the same
  * tokenization.  */
message TokenRefSequence {

  /** The tokenization-relative identifiers for each token that is
    * included in this sequence. */
  repeated int32 token_index = 1;

  /** An optional field that can be used to describe
   * the root of a sentence (if this sequence is a full sentence),
   * the head of a constituent (if this sequence is a constituent),
   * or some other form of "canonical" token in this sequence if,
   * for instance, it is not easy to map this sequence to a another
   * annotation that has a head */
  optional int32 anchor_token_index = 2 [default=-1];

  /** The UUID of the tokenization that contains the tokens. */
  required UUID tokenization_id = 3;

  // The text span associated with this TokenRefSequence.
  optional TextSpan text_span = 4;

  // The audio span associated with this TokenRefSequence.
  optional AudioSpan audio_span = 5;
  
}

/** A theory (or set of alternative theories) about the sequence of
  * tokens that make up a sentence.
  *
  * This message type is used to record the output of not just for
  * tokenizers, but also for a wide variety of other tools, including
  * machine translation systems, text normalizers, part-of-speech
  * taggers, and stemmers.
  * 
  * Each Tokenization is encoded using either a single list of tokens,
  * or a TokenLattice.  (If you want to encode an n-best list, then
  * you should store it as n separate Tokenization objects.)  The
  * "kind" field is used to indicate whether this Tokenization contains
  * a list of tokens or a TokenLattice.
  *
  * The confidence value for each sequence is determined by combining
  * the confidence from the "metadata" field with confidence
  * information from individual token sequences as follows:
  *
  * <ul>
  *   <li> For n-best lists: 
  *        metadata.confidence </li>
  *   <li> For lattices:
  *        metadata.confidence * exp(-sum(arc.weight)) </li>
  * </ul>
  * 
  * Note: in some cases (such as the output of a machine translation
  * tool), the order of the tokens in a token sequence may not
  * correspond with the order of their original text span offsets.
  */
message Tokenization {
  /** Unique identifier for this tokenization. */
  required UUID uuid = 1;

  /** Information about where this tokenization came from. */
  optional AnnotationMetadata metadata = 2;

  /** Enumerated value indicating whether this tokenization is
   * implemented using an n-best list or a lattice. */
  optional Kind kind = 3;
  enum Kind {TOKEN_LIST = 1; TOKEN_LATTICE = 2;}

  /** An ordered list of the tokens in this tokenization.  This field
    * should only have a value if kind==TOKEN_LIST. */
  repeated Token token = 4;

  /** A lattice that compactly describes a set of token sequences that
    * might make up this tokenization.  This field should only have a
    * value if kind==LATTICE. */
  optional TokenLattice lattice = 5;

  /** A lattice structure that assigns scores to a set of token
    * sequences.  The lattice is encoded as an FSA, where states are
    * identified by integers, and each arc is annotated with an
    * optional tokens and a weight.  (Arcs with no tokens are
    * "epsilon" arcs.)  The lattice has a single start state and a
    * single end state.  (You can use epsilon edges to simulate
    * multiple start states or multiple end states, if desired.)
    * 
    * The score of a path through the lattice is the sum of the weights
    * of the arcs that make up that path.  A path with a lower score
    * is considered "better" than a path with a higher score.  
    * 
    * If possible, path scores should be negative log likelihoods
    * (with base e -- e.g. if P=1, then weight=0; and if P=0.5, then
    * weight=0.693).  Furthermore, if possible, the path scores should
    * be globally normalized (i.e., they should encode probabilities).
    * This will allow for them to be combined with other information
    * in a reasonable way when determining confidences for system
    * outputs.
    *
    * TokenLattices should never contain any paths with cycles.  Every
    * arc in the lattice should be included in some path from the start
    * state to the end state.
    */
  message TokenLattice {
    /** Start state for this token lattice. */
    optional int32 start_state = 1   [default=0];
  
    /** End state for this token lattice. */
    optional int32 end_state = 2     [default=0];
  
    /** Type for arcs.  For epsilon edges, leave 'token' blank. */
    message Arc {
      optional int32 src = 1;      //!< state identifier
      optional int32 dst = 2;      //!< state identifier
      optional Token token = 3;    //!< leave empty for epsilon edge
      optional double weight = 4;  //!< additive weight; lower is better
    }
  
    /** The set of arcs that make up this lattice (order is
      * unspecified). */
    repeated Arc arc = 3;

    /** A cached copy of the one-best path through the token lattice.
     * This field must always be kept consistent with the arc-based
     * lattice: if you edit the lattice, then you must either delete
     * this field or ensure that it is up-to-date. */
    optional LatticePath cached_best_path = 4;
    message LatticePath {
      optional float weight = 1;
      repeated Token token = 2;
    }
  }

  /** Theories about various annotations of the tokens
   * in this tokenization. */
  repeated TokenTagging pos_tags = 6;
  repeated TokenTagging ner_tags = 7;
  repeated TokenTagging lemmas = 8;
  repeated TokenTagging lang_ids = 9;

  /** Theories about the parse structure of this Tokenization. */
  repeated Parse parse = 10;
  repeated DependencyParse dependency_parse = 11;
}

/** A theory about some token-level annotation.
 * The TokenTagging consists of a mapping from tokens
 * (using token ids) to string tags (e.g. part-of-speech tags or lemmas).
 *
 * The mapping defined by a TokenTagging may be partial --
 * i.e., some tokens may not be assigned any part of speech tags.
 *
 * For lattice tokenizations, you may need to create multiple
 * part-of-speech taggings (for different paths through the lattice),
 * since the appropriate tag for a given token may depend on the path
 * taken.  For example, you might define a separate
 * TokenTagging for each of the top K paths, which leaves all
 * tokens that are not part of the path unlabeled.
 *
 * Currently, we use strings to encode annotations. In
 * the future, we may add fields for encoding specific tag sets
 * (eg treebank tags), or for adding compound tags.
 */
message TokenTagging {
  /** Unique identifier for this annotation */
  required UUID uuid = 1;

  /** Information about where the annotation came from.
   * This should be used to tell between gold-standard annotations
   * and automatically-generated theories about the data */
  optional AnnotationMetadata metadata = 2;

  /** The mapping from tokens to annotations.
   * This may be a partial mapping. */
  repeated TaggedToken tagged_token = 3;

  message TaggedToken {
    /** A pointer to the token being tagged. */
    optional int32 token_index = 1;

    /** A string containing the annotation.
	 *  If the tag set you are using is not case sensitive,
	 * then all part of speech tags should be normalized to upper case. */
    optional string tag = 2;

    /** Confidence of the annotation. */
    optional float confidence = 3;
  }
}


//===========================================================================
// Parse Trees
//===========================================================================

/** A theory about the syntactic parse of a sentence.
 *
 * \note If we add support for parse forests in the future, then it
 * will most likely be done by adding a new field (e.g.
 * "<tt>forest_root</tt>") that uses a new message type to encode the
 * forest.  A "<tt>kind</tt>" field might also be added (analogous to
 * <tt>Tokenization.kind</tt>) to indicate whether a parse is encoded
 * using a simple tree or a parse forest.
 */
message Parse {
  /** Unique identifier for this parse. */
  required UUID uuid = 1;

  /** Information about where this parse came from. */
  optional AnnotationMetadata metadata = 2;

  /** The root constituent of this parse */
  optional Constituent root = 3;

  /** A single parse constituent (or "phrase"). */
  message Constituent {
    /** A parse-relative identifier for this consistuent.  Together
    * with the UUID for a Parse, this can be used to define
    * pointers to specific constituents. */
    required int32 id = 1;

    optional string tag = 2;

    /** The list of parse constituents that are directly dominated by
      * this constituent. */
    repeated Constituent child = 3;

    /** The list of pointers to the tokens dominated by this
      * constituent.  Typically, this field will only be defined for
      * leaf constituents (i.e., constituents with no children).  For
      * many parsers, len(tokens) will always be either 1 (for leaf
      * constituents) or 0 (for non-leaf constituents). */
    optional TokenRefSequence token_sequence = 4;

    /** The index of the head child of this constituent.  I.e., the
      * head child of constituent <tt>c</tt> is
      * <tt>c.children[c.head_child_index]</tt>.  A value of -1
      * indicates that no child head was identified. */
    optional sint32 head_child_index = 5 [default=-1];
  }
}

/**
 * represents a dependency parse with typed edges
 */
message DependencyParse {

  required UUID uuid = 1;
  optional AnnotationMetadata metadata = 2;
  repeated Dependency dependency = 3;

  message Dependency {
  	optional int32 gov = 1;	// will be null for ROOT token (only)
	required int32 dep = 2;
	optional string edge_type = 3;
  }
}

//===========================================================================
// Audio Data
//===========================================================================

/** A sound wave.  A separate optional field is defined for each
  * suppported format.  Typically, a Sound object will only define
  * a single field.
  *
  * Note: we may want to have separate fields for separate channels
  * (left vs right), etc.
  */
message Sound {
  // Todo: decide what sound-file types we want to support.
  optional bytes wav = 1;
  optional bytes mp3 = 2;
  optional bytes sph = 3;

  /** An absolute path to a file on disk where the sound file can be
   * found.  It is assumed that this path will be accessable from any
   * machine that the system is run on (i.e., it should be a shared
   * disk, or possibly a mirrored directory). */
  optional string path = 4;
}

//===========================================================================
// Metadata
//===========================================================================

/** Metadata associated with an annotation or a set of annotations,
  * that identifies where those annotations came from. */
message AnnotationMetadata {
  /** The name of the tool that generated this annotation. */
  optional string tool = 1;

  /** The time at which this annotation was generated (in unix time
   * UTC -- i.e., seconds since January 1, 1970). */
  optional int64 timestamp = 2;

  /** Confidence score.  To do: define what this means!!! */
  optional float confidence = 3;

  // A Digest, carrying over any information the annotation metadata
  // wishes to carry over. 
  optional Digest digest = 4;
}

/** Analytic-specific information about an attribute or edge.  Digests
 * are used to combine information from multiple sources to generate a
 * unified value.  The digests generated by an analytic will only ever
 * be used by that same analytic, so analytics can feel free to encode
 * information in whatever way is convenient. */
message Digest {
  /** The following fields define various ways you can store the
   * digest data (for convenience).  If none of these meets your
   * needs, then serialize the digest to a byte sequence and store it
   * in bytes_value. */
  optional bytes bytes_value = 1;
  optional int64 int64_value = 2;
  optional double double_value = 3;
  optional string string_value = 4;
  repeated int64 int64_list = 5;
  repeated double double_list = 6;
  repeated string string_list = 7;
}

//===========================================================================
// Entities
//===========================================================================

/**
 * A single referent (or "entity") that is referred to at least once
 * in a given communication, along with pointers to all of the
 * references to that referent.  The referent's type (e.g., is it a
 * person, or a location, or an organization, etc) is also recorded.
 * 
 * Because each Entity contains pointers to all references to a
 * referent with a given communication, an Entity can be
 * thought of as a coreference set.
 */
message Entity {
  /** Unique identifier for this entity. */
  required UUID uuid = 1;

  /** An list of pointers to all of the mentions of this Entity's
   * referent.  (type=EntityMention) */
  repeated UUID mention_id = 4;

  /** The basic type of this entity's referent. */
  optional Type entity_type = 3;

  /** An enumerated type used to record referent types (aka "entity
   * types") for Entities and EntityMentions. 
   *
   * In the future, we may add support for encoding entity subtypes as
   * well.  This would most likely be accomplished by adding a second
   * field with a new enumerated type whose values correspond to fully
   * specified subtypes (eg "PERSON_INDIVIDUAL" vs "PERSON_GROUP").
   */
  enum Type { // Renamed from "TYPE"
    PERSON = 1;
    ORGANIZATION = 2;
    GPE = 3;
    OTHER = 4;
    DATE = 5;
    FACILITY = 6;
    VEHICLE = 7;
    WEAPON = 8;
    LOCATION = 9;
    TIME = 10;
    URL = 11;
    EMAIL = 12;
    MONEY = 13;
    PERCENTAGE = 14; /** XX is this different from PERCENT?? */
    PHONE_NUMBER = 15;
    OCCUPATION = 16;
    CHEMICAL = 17;
    AGE = 18;
    PERCENT = 19;
    PERSON_NN = 20;
    GPE_ITE = 21;
    ORGANIZATION_ITE = 22;
    JOB_TITLE = 23;
    UNKNOWN = 24;
    SET = 25; 				// From TimeML Timex
    DURATION = 26; 			// From TimeML Timex 
    // This list is expected to grow over time.
  }

  /** Confidence score for this individual entity.  You can also set a
   * confidence score for an entire EntitySet using the EntitySet's
   * metadata. */
  optional float confidence = 6;

  /** A string containing a representative, canonical, or "best" name
   * for this entity's referent.  This string may match one of the
   * mentions' text strings, but it is not required to. */
  optional string canonical_name = 5;
}

/** A theory about the set of entities that are present in a
 * message.  See also: Entity.*/
message EntitySet {
  /** Unique identifier for this set. */
  required UUID uuid = 1;

  /** Information about where this set came from. */
  optional AnnotationMetadata metadata = 2;

  /** List of entities in this set. */
  repeated Entity entity = 3;
}

//===========================================================================
// Entity Mentions
//===========================================================================

/** A span of text with a specific referent, such as a person,
 * organization, or time.  Things that can be referred to by a mention
 * are called "entities."
 * 
 * It is left up to individual EntityMention taggers to decide which
 * referent types and phrase types to identify.  For example, some
 * EntityMention taggers may only identify proper nouns, or may only
 * identify EntityMentions that refer to people.
 *
 * Each EntityMention consists of a sequence of tokens.  This sequence
 * is usually annotated with information about the referent type
 * (e.g., is it a person, or a location, or an organization, etc) as
 * well as the phrase type (is it a name, pronoun, common noun, etc.).
 *
 * EntityMentions typically consist of a single noun phrase; however,
 * other phrase types may also be marked as mentions.  For
 * example, in the phrase "French hotel," the adjective "French" might
 * be marked as a mention for France.
 */
message EntityMention {
  /** A unique idenifier for this entity mention.*/
  required UUID uuid = 1;

  /** The set of tokens that constitute this mention. */
  required TokenRefSequence tokens = 6;

  /** The type of referent that is referred to by this mention. */
  optional Entity.Type entity_type = 4;

  /** The phrase type of the tokens that constitute this mention. */
  optional PhraseType phrase_type = 3;
  enum PhraseType {        // Renamed from "TYPE"
    NAME = 1;              //!< aka "proper noun"
    PRONOUN = 2;
    COMMON_NOUN = 3;
    OTHER = 4;
    APPOSITIVE = 5;
    LIST = 6;
  }

  /** A confidence score for this individual mention.  You can also
   * set a confidence score for an entire EntityMentionSet using the
   * EntityMentionSet's metadata. */
  optional float confidence = 11;

  /** The text content of this entity mention.  This field is
   * typically redundant with the 'token_sequence' field, and may not
   * be generated by all analytics. */
  optional string text = 2;
}

/**
 * A theory about the set of entity mentions that are present in a
 * message.  See also: EntityMention
 *
 * This type does not represent a coreference relationship, which is handled by Entity.
 * This type is meant to represent the output of a entity-mention-identifier,
 * which is often a part of an in-doc coreference system.
 */
message EntityMentionSet {
  /** Unique identifier for this set. */
  required UUID uuid = 1;

  /** Information about where this set came from. */
  optional AnnotationMetadata metadata = 2;

  /** List of mentions in this set. */
  repeated EntityMention mention = 3;
}

/** A pointer to an entity mention.  This class is mainly intended for
 * use when pointing to an entity mention from some data structure
 * outside the communication (e.g., from a knowledge graph vertex). */
message EntityMentionRef {

  /** The UUID of the entity mention that is being pointed at. (type=EntityMention) */
  optional UUID entity_mention_id = 1;

  /** The corpus-relative communication identifier for the
   * communication that contains the mention that is being pointed at.
   *
   * \see CommunicationsGUID.communication_id.
   */
  optional UUID communication_id = 3;
}


//===========================================================================
// Situations
//===========================================================================

/** A single situation, along with pointers to situation mentions that
 * provide evidence for the situation.  "Situations" include events,
 * relations, facts, sentiments, and beliefs.  Each situation has a
 * core type (such as EVENT or SENTIMENT), along with an optional
 * subtype based on its core type (e.g., event_type=CONTACT_MEET), and
 * a set of zero or more unordered arguments. */
message Situation {
  /** Unique identifier for this situation. */
  required UUID uuid = 1;

  /** The core type of this situation (eg EVENT or SENTIMENT) */
  optional Type situation_type = 2;

  /** The arguments for this situation.  Each argument consists of a
   * role and a value.  It is possible for an situation to have
   * multiple arguments with the same role.  Arguments are
   * unordered. */
  repeated Argument argument = 3;

  /** Ids of the mentions of this situation in a communication
   * (type=SituationMention) */
  repeated UUID mention_id = 4;

  /** An list of pointers to SituationMentions that provide
   * justification for this situation.  These mentions may be either
   * direct mentions of the situation, or indirect evidence. */
  repeated Justification justification = 5;

  /** The event type for situations where situation_type=EVENT */
  optional EventType event_type = 50; 

  /** The state type for situations where situation_type=STATE */
  optional StateType state_type = 51;
  
  /** The temporal fact type for situations where situation_type=TEMPORAL_FACT */
  optional TemporalFactType temporal_fact_type = 52;
  
  /** This lemma represents a canonical lemma for the situation kind 
   * when the situation kind cannot be specified by a situation type subtype
   * (ex, when using arbitrary verbs or nominalizations as events which do 
   * not appear in the event_type enumeration).
   * If this kind is grounded in a token sequence from the original text, the
   * appropriate SituationMention should have a reference to the token sequence.
   */
  optional string situation_kind_lemma = 53;
  
  /** The TimeML class for situations representing TimeML events */
  optional TimeMLClass timeml_class = 54;
  
  /** The TimeML tense for situations representing TimeML events */
  optional TimeMLTense timeml_tense = 55;
  
  /** The TimeML aspect for situations representing TimeML events */
  optional TimeMLAspect timeml_aspect = 56;

  /** An "intensity" rating for this situation, typically ranging from
   * 0-1.  In the case of SENTIMENT situations, this is used to record
   * the intensity of the sentiment. */
  optional float intensity = 100;

  /** The polarity of this situation.  In the case of SENTIMENT
   * situations, this is used to record the polarity of the
   * sentiment. */
  optional Polarity polarity = 101;

  /** A confidence score for this individual situation.  You can also
   * set a confidence score for an entire SituationSet using the
   * SituationSet's metadata. */
  optional float confidence = 200;

  /* An enumerated type used to record the core types of situations.
   * These types form a type hierarchy, as follows:
   *
   *   * SITUATION
   *      * FACT
   *         * CAUSAL_FACT
   *         * TEMPORAL_FACT
   *      * EVENT
   *      * STATE (includes ACE-style relations)
   *         * PRIVATE_STATE
   *            * SENTIMENT
   */
  enum Type {
    SITUATION = 0;
    FACT = 100;              //!< Subtype of SITUATION
    CAUSAL_FACT = 110;       //!< Subtype of FACT
    TEMPORAL_FACT = 120;     //!< Subtype of FACT
    EVENT = 200;             //!< Subtype of SITUATION
    STATE = 300;             //!< Subtype of SITUATION
    PRIVATE_STATE = 310;     //!< Subtype of STATE
    SENTIMENT = 311;         //!< Subtype of PRIVATE_STATE
  }

  /** A situation argument, consisting of an argument role and a value.
   * Argument values may be Entities or Situations. */
  message Argument {
    /** The relationship between this argument and the situation that
     * owns it.  The roles that a situation's arguments can take
     * depend on the type of the situation (including subtype
     * information, such as event_type). */
    optional Role role = 1;

    /** A pointer to the value of this argument, if it is explicitly
     * encoded as an Entity or a Situation. */
    optional UUID entity_id = 2;

    // A pointer to the value of this argument, if it is a situation.
    optional UUID situation_id = 3;

    /** Enumerated type used to record the relationship between an
     * argument and the situation that owns it. */
    enum Role {
      OTHER_ROLE = 1;
      PERSON_ROLE = 2;
      TIME_ROLE = 3;
      PLACE_ROLE = 4;
      AGENT_ROLE = 5;
      VICTIM_ROLE = 6;
      INSTRUMENT_ROLE = 7;
      VEHICLE_ROLE = 8;
      ARTIFACT_ROLE = 9;
      PRICE_ROLE = 10;
      ORIGIN_ROLE = 11;
      DESTINATION_ROLE = 12;
      BUYER_ROLE = 13;
      SELLER_ROLE = 14;
      BENEFICIARY_ROLE = 15;
      GIVER_ROLE = 16;
      RECIPIENT_ROLE = 17;
      MONEY_ROLE = 18;
      ORG_ROLE = 19;
      ATTACKER_ROLE = 20;
      TARGET_ROLE = 21;
      ENTITY_ROLE = 22;
      POSITION_ROLE = 23;
      DEFENDANT_ROLE = 24;
      ADJUDICATOR_ROLE = 25;
      PROSECUTOR_ROLE = 26;
      CRIME_ROLE = 27;
      PLAINTIFF_ROLE = 28;
      SENTENCE_ROLE = 29;
      TIME_WITHIN_ROLE = 30;
      TIME_STARTING_ROLE = 31;
      TIME_ENDING_ROLE = 32;
      TIME_BEFORE_ROLE = 33;
      TIME_AFTER_ROLE = 34;
      TIME_HOLDS_ROLE = 35;
      TIME_AT_BEGINNING_ROLE = 36;
      TIME_AT_END_ROLE = 37;
      RELATION_SOURCE_ROLE = 38;
      RELATION_TARGET_ROLE = 39;
    }
  }

  /** A pointer to a SituationMention that provides supporting
   * evidence for this situation, along with information about
   * the nature of the support. */
  message Justification {
    /** An enumerated value used to describe the way in which the
     * justification's mention provides supporting evidence for the
     * situation. */
    optional Type justification_type = 1;

    /** A pointer to the SituationMention itself. */
    required UUID mention = 2;

    /** An optional list of pointers to tokens that are (especially)
     * relevant to the way in which this mention provides
     * justification for the situation.  It is left up to individual
     * analytics to decide what tokens (if any) they wish to include
     * in this field. */
    repeated TokenRefSequence tokens = 3;

    /** The way in which the justification's mention provides evidence
     * for the situation.*/
    enum Type {
      DIRECT_MENTION = 1;
      IMPLICIT = 2;
      // this list will grow over time
    }
  }

  /** An enumerated type used to record event types for Situations
   * and SituationMentions where situation_type=EVENT. */
  enum EventType {
    OTHER_EVENT = 1;
    //-----------------------------------------------------------------
    // ACE event types:
    //-----------------------------------------------------------------
    BUSINESS_DECLARE_BANKRUPTCY_EVENT = 2;
    BUSINESS_END_ORG_EVENT = 3;
    BUSINESS_MERGE_ORG_EVENT = 4;
    BUSINESS_START_ORG_EVENT = 5;
    CONFLICT_ATTACK_EVENT = 6;
    CONFLICT_DEMONSTRATE_EVENT = 7;
    CONTACT_MEET_EVENT = 8;
    CONTACT_PHONE_WRITE_EVENT = 9;
    JUSTICE_ACQUIT_EVENT = 10;
    JUSTICE_APPEAL_EVENT = 11;
    JUSTICE_ARREST_JAIL_EVENT = 12;
    JUSTICE_CHARGE_INDICT_EVENT = 13;
    JUSTICE_CONVICT_EVENT = 14;
    JUSTICE_EXECUTE_EVENT = 15;
    JUSTICE_EXTRADITE_EVENT = 16;
    JUSTICE_FINE_EVENT = 17;
    JUSTICE_PARDON_EVENT = 18;
    JUSTICE_RELEASE_PAROLE_EVENT = 19;
    JUSTICE_SENTENCE_EVENT = 20;
    JUSTICE_SUE_EVENT = 21;
    JUSTICE_TRIAL_HEARING_EVENT = 22;
    LIFE_BE_BORN_EVENT = 23;
    LIFE_DIE_EVENT = 24;
    LIFE_DIVORCE_EVENT = 25;
    LIFE_INJURE_EVENT = 26;
    LIFE_MARRY_EVENT = 27;
    MOVEMENT_TRANSPORT_EVENT = 28;
    PERSONNEL_ELECT_EVENT = 29;
    PERSONNEL_END_POSITION_EVENT = 30;
    PERSONNEL_NOMINATE_EVENT = 31;
    PERSONNEL_START_POSITION_EVENT = 32;
    QUOTATION_DEFINITE_EVENT = 33;
    QUOTATION_POSSIBLE_EVENT = 34;
    TRANSACTION_TRANSFER_MONEY_EVENT = 35;
    TRANSACTION_TRANSFER_OWNERSHIP_EVENT = 36;
  }

  /** An enumerated type used to record event types for Situations
   * and SituationMentions where situation_type=STATE. */
  enum StateType {
    OTHER_STATE = 1;
    //-----------------------------------------------------------------
    // ACE 2004 relations:
    //-----------------------------------------------------------------
    ART_INVENTOR_OR_MANUFACTURER_STATE = 37;
    ART_OTHER_STATE = 38;
    ART_USER_OR_OWNER_STATE = 39;
    DISC_STATE = 40;
    PHYS_LOCATED_STATE = 41; // Also in ACE 2005
    PHYS_NEAR_STATE = 42; // Also in ACE 2005
    PHYS_PART_WHOLE_STATE = 43;
    EMP_ORG_EMPLOY_EXECUTIVE_STATE = 44;
    EMP_ORG_EMPLOY_STAFF_STATE = 45;
    EMP_ORG_EMPLOY_UNDETERMINED_STATE = 46;
    EMP_ORG_MEMBER_OF_GROUP_STATE = 47;
    EMP_ORG_OTHER_STATE = 48;
    EMP_ORG_PARTNER_STATE = 49;
    EMP_ORG_SUBSIDIARY_STATE = 50;
    GPE_AFF_BASED_IN_STATE = 51;
    GPE_AFF_CITIZEN_OR_RESIDENT_STATE = 52;
    GPE_AFF_OTHER_STATE = 53;
    OTHER_AFF_ETHNIC_STATE = 54;
    OTHER_AFF_IDEOLOGY_STATE = 55;
    OTHER_AFF_OTHER_STATE = 56;
    PER_SOC_BUSINESS_STATE = 57; // Also in ACE 2005
    PER_SOC_FAMILY_STATE = 58; // Also in ACE 2005
    PER_SOC_OTHER_STATE = 59;
    //-----------------------------------------------------------------
    // ACE 2005 relations:
    //-----------------------------------------------------------------
    ART_USER_OWNER_INVENTOR_MANUFACTURER_STATE = 60;
    GEN_AFF_CITIZEN_RESIDENT_RELIGION_ETHNICITY_STATE = 61;
    GEN_AFF_ORG_LOCATION_STATE = 62;
    ORG_AFF_EMPLOYMENT_STATE = 63;
    ORG_AFF_FOUNDER_STATE = 64;
    ORG_AFF_OWNERSHIP_STATE = 65;
    ORG_AFF_STUDENT_ALUM_STATE = 66;
    ORG_AFF_SPORTS_AFFILIATION_STATE = 67;
    ORG_AFF_INVESTOR_SHAREHOLDER_STATE = 68;
    ORG_AFF_MEMBERSHIP_STATE = 69;
    PART_WHOLE_ARTIFACT_STATE = 70;
    PART_WHOLE_GEOGRAPHICAL_STATE = 71;
    PART_WHOLE_SUBSIDIARY_STATE = 72;
    PER_SOC_LASTING_PERSONAL_STATE = 73;
    //-----------------------------------------------------------------
    // This list is expected to grow over time.
  }
  
  /** An enumerated type used to record event types for Situations
   * and SituationMentions where situation_type=TEMPORAL_FACT. */
  enum TemporalFactType {
    BEFORE_TEMPORAL_FACT = 1;
    AFTER_TEMPORAL_FACT = 2;
    SIMULTANEOUS_TEMPORAL_FACT = 3;
    INCLUDES_TEMPORAL_FACT = 4;
    IS_INCLUDED_BY_TEMPORAL_FACT = 5;
    VAGUE_TEMPORAL_FACT = 6;
  }

  /** An enumeration used to record the TimeML class of a situation */
  enum TimeMLClass {
    OCCURRENCE_CLASS = 1;
    PERCEPTION_CLASS = 2;
    REPORTING_CLASS = 3;
    ASPECTUAL_CLASS = 4;
    STATE_CLASS = 5;
    I_STATE_CLASS = 6;
    I_ACTION_CLASS = 7;
  }
  
  /** An enumeration used to record the TimeML tense of a situation */
  enum TimeMLTense {
    FUTURE_TENSE = 1;
    INFINITIVE_TENSE = 2;
    PAST_TENSE = 3;
    PASTPART_TENSE = 4;
    PRESENT_TENSE = 5;
    PRESPART_TENSE = 6;
    NONE_TENSE = 7;
  }
  
  /** An enumeration used to record the TimeML aspect of a situation */
  enum TimeMLAspect {
    PROGRESSIVE_ASPECT = 1;
    PERFECTIVE_ASPECT = 2;
    PERFECTIVE_PROGRESSIVE_ASPECT = 3;
    NONE_ASPECT = 4;
  }

  /** An enumeration used to record the polarity of a situation.
   * This is primarily intended for use with SENTIMENT situations. */
  enum Polarity {
    POSITIVE_POLARITY = 1;
    NEGATIVE_POLARITY = 2;
    NEUTRAL_POLARITY = 3;
    BOTH_POLARITY = 4;
  }
}

/** A theory about the set of situations that are present in a 
 * message.  See also: Situation */
message SituationSet {
  /** Unique identifier for this set. */
  required UUID uuid = 1;

  /** Information about where this set came from. */
  optional AnnotationMetadata metadata = 2;

  /** List of mentions in this set. */
  repeated Situation situation = 3;
}

//===========================================================================
// Situation Mentions
//===========================================================================

/** A concrete mention of a situation, where "situations" include
 * events, relations, facts, sentiments, and beliefs.  Each situation
 * has a core type (such as EVENT or SENTIMENT), along with an
 * optional subtype based on its core type (e.g.,
 * event_type=CONTACT_MEET), and a set of zero or more unordered
 * arguments. */
message SituationMention {
  /** Unique identifier for this situation. */
  required UUID uuid = 1;

  /** The text content of this situation mention.  This field is
   * often redundant with the 'tokens' field, and may not
   * be generated by all analytics. */

  optional string text = 2;

  /** The core type of this situation (eg EVENT or SENTIMENT) */
  optional Situation.Type situation_type = 3;

  /** The arguments for this situation mention.  Each argument
   * consists of a role and a value.  It is possible for an situation
   * to have multiple arguments with the same role.  Arguments are
   * unordered. */
  repeated Argument argument = 4;

  /** The event type for situations where situation_type=EVENT */
  optional Situation.EventType event_type = 50;

  /** The state type for situations where situation_type=STATE */
  optional Situation.StateType state_type = 51;

  /** An "intensity" rating for the situation, typically ranging from
   * 0-1.  In the case of SENTIMENT situations, this is used to record
   * the intensity of the sentiment. */
  optional float intensity = 100;

  /** The polarity of this situation.  In the case of SENTIMENT
   * situations, this is used to record the polarity of the
   * sentiment. */
  optional Situation.Polarity polarity = 101;

  /** An optional pointer to tokens that are (especially)
   * relevant to this situation mention.  It is left up to individual
   * analytics to decide what tokens (if any) they wish to include in
   * this field.  In particular, it is not specified whether the
   * arguments' tokens should be included. */
  required TokenRefSequence tokens = 150;

  /** A confidence score for this individual situation mention.  You
   * can also set a confidence score for an entire SituationMentionSet
   * using the SituationMentionSet's metadata. */
  optional float confidence = 200;

  /** A situation mention argument, consisting of an argument role and
   * a value.  Argument values may be EntityMentions or
   * SituationMentions. */
  message Argument {
    /** The relationship between this argument and the situation
     * mention that owns it. */
    optional Situation.Argument.Role role = 1;

    // A pointer to the value of this argument, if it is explicitly encoded as an EntityMention.
    optional UUID entity_mention_id = 2;
    
    // A pointer to the value of this argument, if it is explicitly encoded as an SituationMention. 
    optional UUID situation_mention_id = 3;

    /** New roles should usually be added to the enum, but for use
     cases with many varied and possibly dynamic role names, this can be
     used.  Presumably this would only be used in a prototype stage of an
     analytic, with roles eventually "hardening" and moving to the enum. */
    optional string role_label = 4;
  }
}

/** A theory about the set of situation mentions that are present in a
 * message.  See also: SituationMention */
message SituationMentionSet {
  /** Unique identifier for this set. */
  required UUID uuid = 1;

  /** Information about where this set came from. */
  optional AnnotationMetadata metadata = 2;

  /** List of mentions in this set. */
  repeated SituationMention mention = 3;
}


/**
 * a meaniningful set of Communications, possibly
 * with some coreference annotations.
 */
message Discourse {	

	// the ID associated with this Discourse object. 
	required UUID id = 1;

	/**
	 * the tool that identified this set of Communications
	 * (not the tool that determined any coreference assessments)
	 */
	required AnnotationMetadata metadata = 2;

	/**
	 * theories about the coreference relationships between
	 * Entity or Situtation discussed in this set of Communications.
	 */
	repeated DiscourseAnnotation annotation = 3;

	/**
	 * a theory of cross-doc Entity/Situtation coreference
	 */
	message DiscourseAnnotation {	// come in gold and synthetic varieties
		// The ID associated with this DiscourseAnnotation.
		required UUID id = 1;

		// The metadata associated with the tool responsible for suggesting this DiscourseAnnotation. 
		required AnnotationMetadata metadata = 2;

		// A set of DiscourseEntities suggested by this DiscourseAnnotation object.
		repeated DiscourseEntity discourse_entity = 3;			// all entities mentioned in this Discourse
		
		// A set of DiscourseSituations suggested by this DiscourseAnnotation object. 
		repeated DiscourseSituation discourse_situation = 4;		// all situations mentioned in this Discourse
	}
}

/**
 * represents one Entity in a cross-doc situation coref/alignment
 */
message DiscourseEntity {
	required UUID id = 1;
	repeated EntityRef entity_ref = 2;			// all mentions of this entity
	optional float confidence = 3;
}

/**
 * represents one Situation in a cross-doc situation coref/alignment
 */
message DiscourseSituation {
	required UUID id = 1;
	repeated SituationRef situation_ref = 2;		// all mentions of this situation
	optional float confidence = 3;
}

/**
 * A reference to an Entity in a Communication.
 */
message EntityRef {
	required UUID entity_id = 1;		// type=Entity
	required UUID communication_id = 2;	// type=Communication
}

/**
 * A reference to a Situation in a Communication.
 */
message SituationRef {
	required UUID situation_id = 1;		// type=Situation
	required UUID communication_id = 2;	// type=Communication
}

